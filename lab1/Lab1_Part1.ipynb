{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7a705d20",
   "metadata": {},
   "source": [
    "# Lab1 â€” PyTorch Foundations for Computer Vision\n",
    "\n",
    "**Course**: Deep Learning for Image Analysis \n",
    "\n",
    "**Class**: M2 IASD App  \n",
    "\n",
    "**Professor**: Mehyar MLAWEH\n",
    "\n",
    "---\n",
    "\n",
    "## Objectives\n",
    "By the end of this lab, you should be able to:\n",
    "\n",
    "- Understand how **neurons and layers** are implemented in PyTorch\n",
    "- Manipulate **tensors** and reason about shapes\n",
    "- Use **autograd** to compute gradients\n",
    "- Implement a **training loop** yourself\n",
    "- Connect theory (neurons, loss, backprop) to actual code\n",
    "\n",
    "âš ï¸ This notebook is **intentionally incomplete**.  \n",
    "Whenever you see **`# TODO`**, you are expected to write code."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e07470cd",
   "metadata": {},
   "source": [
    "\n",
    "**Deadline:** ðŸ—“ï¸ **Saturday, February 7th (23:59)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60119f3a",
   "metadata": {},
   "source": [
    "## ðŸ¤– A small (honest) note before you start\n",
    "\n",
    "Letâ€™s be real for a second.\n",
    "\n",
    " I know you **can use LLMs (ChatGPT, Copilot, Claude, etc.)** to help you with this lab.  \n",
    "And yes, **I use them too**, so donâ€™t worry ðŸ˜„\n",
    "\n",
    "ðŸ‘‰ **You are allowed to use AI tools.**  \n",
    "But hereâ€™s the deal:\n",
    "\n",
    "- Donâ€™t just **copyâ€“paste** code you donâ€™t understand  \n",
    "- Take time to **read, question, and modify** what the model gives you  \n",
    "- If you can solve a block **by yourself, without AI**, thatâ€™s excellent \n",
    "\n",
    "Remember:\n",
    "\n",
    "> AI can write code for you, but **only you can understand it** â€” and understanding is what matters for exams, projects, and real work.\n",
    "\n",
    "Use these tools **as assistants, not as replacements for thinking**.\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸ“š Useful documentation (highly recommended)\n",
    "\n",
    "You will often find answers faster (and more reliably) by checking the official documentation:\n",
    "\n",
    "- **PyTorch main documentation**  \n",
    "  https://pytorch.org/docs/stable/index.html\n",
    "\n",
    "- **PyTorch tensors**  \n",
    "  https://pytorch.org/docs/stable/tensors.html\n",
    "\n",
    "- **Neural network modules (`torch.nn`)**  \n",
    "  https://pytorch.org/docs/stable/nn.html\n",
    "\n",
    "- **Loss functions** (`BCEWithLogitsLoss`, CrossEntropy, etc.)  \n",
    "  https://pytorch.org/docs/stable/nn.html#loss-functions\n",
    "\n",
    "- **Optimizers** (`SGD`, `Adam`, â€¦)  \n",
    "  https://pytorch.org/docs/stable/optim.html\n",
    "\n",
    "If you learn how to **navigate the documentation**, you are already thinking like a real AI engineer ðŸ‘Œ\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "6cf19b77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in ./.venv/lib/python3.13/site-packages (2.4.2)\n",
      "Requirement already satisfied: matplotlib in ./.venv/lib/python3.13/site-packages (3.10.8)\n",
      "Requirement already satisfied: torch in ./.venv/lib/python3.13/site-packages (2.10.0)\n",
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-1.8.0-cp313-cp313-macosx_12_0_arm64.whl.metadata (11 kB)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in ./.venv/lib/python3.13/site-packages (from matplotlib) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in ./.venv/lib/python3.13/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in ./.venv/lib/python3.13/site-packages (from matplotlib) (4.61.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in ./.venv/lib/python3.13/site-packages (from matplotlib) (1.4.9)\n",
      "Requirement already satisfied: packaging>=20.0 in ./.venv/lib/python3.13/site-packages (from matplotlib) (26.0)\n",
      "Requirement already satisfied: pillow>=8 in ./.venv/lib/python3.13/site-packages (from matplotlib) (12.1.0)\n",
      "Requirement already satisfied: pyparsing>=3 in ./.venv/lib/python3.13/site-packages (from matplotlib) (3.3.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in ./.venv/lib/python3.13/site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: filelock in ./.venv/lib/python3.13/site-packages (from torch) (3.20.3)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in ./.venv/lib/python3.13/site-packages (from torch) (4.15.0)\n",
      "Requirement already satisfied: setuptools in ./.venv/lib/python3.13/site-packages (from torch) (80.10.2)\n",
      "Requirement already satisfied: sympy>=1.13.3 in ./.venv/lib/python3.13/site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in ./.venv/lib/python3.13/site-packages (from torch) (3.6.1)\n",
      "Requirement already satisfied: jinja2 in ./.venv/lib/python3.13/site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec>=0.8.5 in ./.venv/lib/python3.13/site-packages (from torch) (2026.1.0)\n",
      "Collecting scipy>=1.10.0 (from scikit-learn)\n",
      "  Downloading scipy-1.17.0-cp313-cp313-macosx_14_0_arm64.whl.metadata (62 kB)\n",
      "Collecting joblib>=1.3.0 (from scikit-learn)\n",
      "  Using cached joblib-1.5.3-py3-none-any.whl.metadata (5.5 kB)\n",
      "Collecting threadpoolctl>=3.2.0 (from scikit-learn)\n",
      "  Using cached threadpoolctl-3.6.0-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: six>=1.5 in ./.venv/lib/python3.13/site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in ./.venv/lib/python3.13/site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./.venv/lib/python3.13/site-packages (from jinja2->torch) (3.0.3)\n",
      "Downloading scikit_learn-1.8.0-cp313-cp313-macosx_12_0_arm64.whl (8.0 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m8.0/8.0 MB\u001b[0m \u001b[31m17.0 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached joblib-1.5.3-py3-none-any.whl (309 kB)\n",
      "Downloading scipy-1.17.0-cp313-cp313-macosx_14_0_arm64.whl (20.1 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m20.1/20.1 MB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m  \u001b[33m0:00:01\u001b[0mm0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hUsing cached threadpoolctl-3.6.0-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: threadpoolctl, scipy, joblib, scikit-learn\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m4/4\u001b[0m [scikit-learn][0m [scikit-learn]\n",
      "\u001b[1A\u001b[2KSuccessfully installed joblib-1.5.3 scikit-learn-1.8.0 scipy-1.17.0 threadpoolctl-3.6.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m26.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# Installation des modules\n",
    "%pip install numpy matplotlib torch scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f278eff5",
   "metadata": {},
   "source": [
    "## PART I"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de614322",
   "metadata": {},
   "source": [
    "## 0) Colab setup â€” GPU check\n",
    "\n",
    "**Instructions**\n",
    "1. In Colab: `Runtime â†’ Change runtime type to GPU T4` \n",
    "2. Select **GPU**\n",
    "3. Save and restart runtime\n",
    "\n",
    "Then run the cell below.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72e3ba23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.10.0\n",
      "CUDA available: False\n",
      "Using device: mps\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "print(\"PyTorch version:\", torch.__version__)\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "\n",
    "# TODO: set the device correctly (cuda if available, else cpu)\n",
    "device = (\n",
    "        'cuda' if torch.cuda.is_available() \n",
    "        else 'mps' if torch.mps.is_available\n",
    "        else 'cpu'\n",
    ")\n",
    "\n",
    "print(\"Using device:\", device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcc7ceb1",
   "metadata": {},
   "source": [
    "## 1) Imports and reproducibility\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0ce2798",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x112789030>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# TODO: fix the random seed for reproducibility\n",
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9349f5a5",
   "metadata": {},
   "source": [
    "## 2) PyTorch tensors and shapes\n",
    "\n",
    "Tensors are multi-dimensional arrays that support:\n",
    "- GPU acceleration\n",
    "- automatic differentiation\n",
    "\n",
    "Understanding **shapes** is critical in deep learning.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d2998b3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a shape: torch.Size([3])\n",
      "b shape: torch.Size([4, 5])\n"
     ]
    }
   ],
   "source": [
    "# Examples\n",
    "a = torch.tensor([1.0, 2.0, 3.0])\n",
    "b = torch.randn(4, 5)\n",
    "\n",
    "print(\"a shape:\", a.shape)\n",
    "print(\"b shape:\", b.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d675977",
   "metadata": {},
   "source": [
    "### ðŸ” Question (answer inside the markdown)\n",
    "- How many dimensions does tensor `b` have?\n",
    "    > `b` is a 2-dimensional tensor, that is a matrix.\n",
    "\n",
    "- What does each dimension represent conceptually?\n",
    "    > Conceptually, the first dimension is the number of **rows** and the second one reprensents the number of **columns**. Commonly, each row is an individual and each column is a particular feature (e.g. age, size, ...)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ea0588f",
   "metadata": {},
   "source": [
    "### âœ…Tensor operations\n",
    "\n",
    "Complete the following:\n",
    "\n",
    "1. Create a tensor `x` of shape `(8, 3)` with random values  \n",
    "2. Compute:\n",
    "   - the **mean of each column**\n",
    "   - the **L2 norm of each row**\n",
    "3. Normalize `x` **row-wise** using the L2 norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "b4629e99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 3]) torch.Size([3]) torch.Size([8]) torch.Size([8, 3])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# TODO: create x\n",
    "x = torch.randn(8, 3)\n",
    "\n",
    "# TODO: column mean\n",
    "col_mean = x.mean(dim=0) # Mean on the dimension to reduce, here the first dimension to get a tensor of 3 means\n",
    "\n",
    "# TODO: row-wise L2 norm\n",
    "row_norm = torch.linalg.norm(x, ord=2, dim=1) # L2-normalization on the rows\n",
    "\n",
    "# TODO: normalized tensor\n",
    "x_normalized = col_mean / row_norm.view(-1, 1) # Normalization by row \n",
    "\n",
    "print(x.shape, col_mean.shape, row_norm.shape, x_normalized.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d0f8928",
   "metadata": {},
   "source": [
    "## 3) Artificial neuron â€” from math to code\n",
    "\n",
    "A neuron computes:\n",
    "\n",
    "$$\n",
    "z = \\sum_i w_i x_i + b\n",
    "$$\n",
    "\n",
    "Then applies an activation function:\n",
    "\n",
    "$$\n",
    "y = g(z)\n",
    "$$\n",
    "\n",
    "This section connects directly to the theory seen in class.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "6d271c97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-0.8000)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.tensor([1.0, -2.0, 3.0])\n",
    "w = torch.tensor([0.2, 0.4, -0.1])\n",
    "b = torch.tensor(0.1)\n",
    "\n",
    "z = torch.sum(x * w) + b\n",
    "z"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db2d7490",
   "metadata": {},
   "source": [
    "### Activation functions\n",
    "\n",
    "1. Implement **ReLU**\n",
    "2. Implement **Sigmoid**\n",
    "3. Apply both to `z` and compare the outputs\n",
    "\n",
    "Which activation preserves negative values?\n",
    "> By definition, Sigmoid function preserves negative values. Indeed, for any value of $z$, $e^{-z}$ is not zero which implies that $\\frac{1}{1 + e^{-z}}$ is nonzero even when $z \\le 0$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "f307df40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.), tensor(0.3100))"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO\n",
    "def relu(z):\n",
    "    \"\"\"Compute relu(x) = max(x, 0)\"\"\"\n",
    "    return torch.max(z, torch.tensor(0))\n",
    "\n",
    "def sigmoid(z):\n",
    "    \"\"\"Compute sigma(x) = 1 / (1 + exp{-z})\"\"\"\n",
    "    return 1 / (1 + torch.exp(-z))\n",
    "\n",
    "y_relu = relu(z)\n",
    "y_sigmoid = sigmoid(z)\n",
    "y_relu, y_sigmoid\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e764019",
   "metadata": {},
   "source": [
    "## 4) Autograd and gradients\n",
    "\n",
    "PyTorch uses **automatic differentiation** to compute gradients\n",
    "using the **chain rule** (backpropagation).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "50f1aab4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 2.890000104904175\n",
      "grad w: tensor([-3.4000, -6.8000,  3.4000])\n",
      "grad b: tensor(-3.4000)\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([1.0, 2.0, -1.0], requires_grad=True)\n",
    "w = torch.tensor([0.5, -0.3, 0.8], requires_grad=True)\n",
    "b = torch.tensor(0.2, requires_grad=True)\n",
    "\n",
    "z = torch.sum(x * w) + b\n",
    "loss = (z - 1.0) ** 2\n",
    "\n",
    "loss.backward()\n",
    "\n",
    "print(\"loss:\", loss.item())\n",
    "print(\"grad w:\", w.grad)\n",
    "print(\"grad b:\", b.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe2c78a9",
   "metadata": {},
   "source": [
    "### ðŸ” Conceptual question\n",
    "\n",
    "- If `b.grad > 0`, should `b` increase or decrease after a gradient descent step?\n",
    "Explain **why** in one sentence.\n",
    "> A gradient step is defined by $b \\leftarrow b - \\alpha \\nabla f(b)$, so $b$ will decrease after this step. Indeed, as the learning rate is positive, the product of the learning rate with the gradient of $b$ is positive.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5bdee3e",
   "metadata": {},
   "source": [
    "## 5) Toy classification dataset\n",
    "\n",
    "We create a **linearly separable** dataset.\n",
    "\n",
    "Label rule:\n",
    "- class = 1 if `xâ‚ + xâ‚‚ + xâ‚ƒ > 0`\n",
    "- else class = 0\n",
    "\n",
    "This mimics a very simple classification problem.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "15c8bc6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import model_selection\n",
    "\n",
    "n, d = 500, 3\n",
    "\n",
    "# TODO: generate a dataset of size N=500 with 3 features\n",
    "X = torch.randn(n,d)\n",
    "y = (X.sum(dim=-1) > 0).float().view(-1,1)  # shape (N, 1)\n",
    "\n",
    "# TODO: split into train (80%) and validation (20%)\n",
    "X_train, X_val, y_train, y_val = model_selection.train_test_split(X, y, train_size=.8, test_size=.2, stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79c16fc2",
   "metadata": {},
   "source": [
    "## 6) Model definition\n",
    "\n",
    "We define a small **MLP** (fully-connected network):\n",
    "\n",
    "`3 â†’ 16 â†’ 8 â†’ 1`\n",
    "\n",
    "Activation: ReLU  \n",
    "Output: raw logits (no sigmoid)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "d7b69f8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_dim=3, output_dim=1):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(input_dim, 16),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(16, 8),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(8, output_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "# TODO: create model and move it to the GPU \n",
    "model = MLP()\n",
    "model = model.to(device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c13b2d2",
   "metadata": {},
   "source": [
    "###  parameters\n",
    "\n",
    "1. Compute **by hand** the total number of parameters\n",
    "> The number of parameters for a layer is : `input_dim x output_dim + output_dim`. The total number of parameters is $(3 \\times 16 + 16) + (16 \\times 8 + 8) + (8 \\times 1 + 1) = 64 + 136 + 9 = 209$\n",
    "\n",
    "2. Verify your answer using PyTorch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "6168e4a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "209"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: count parameters with PyTorch\n",
    "total_params = sum([parameter.numel() for parameter in model.parameters()])\n",
    "total_params\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19f204fb",
   "metadata": {},
   "source": [
    "## 7) Training loop \n",
    "\n",
    "You must complete the full training loop:\n",
    "- forward pass\n",
    "- loss computation\n",
    "- backward pass\n",
    "- optimizer step\n",
    "\n",
    "Loss: `BCEWithLogitsLoss`\n",
    "Optimizer: `SGD`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "d80ad2c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 | loss = 0.7084853053092957\n",
      "Epoch 5 | loss = 0.7016672492027283\n",
      "Epoch 10 | loss = 0.6953663229942322\n",
      "Epoch 15 | loss = 0.6890119910240173\n"
     ]
    }
   ],
   "source": [
    "# TODO: move data to device\n",
    "X_train_d = X_train.to(device)\n",
    "y_train_d = y_train.to(device)\n",
    "X_val_d = X_val.to(device)\n",
    "y_val_d = y_val.to(device)\n",
    "\n",
    "# Number of epochs\n",
    "n_epochs = 20\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.1)\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # TODO: forward\n",
    "    logits = model.forward(X_train_d)\n",
    "\n",
    "    # TODO: loss\n",
    "    loss = criterion(logits, y_train_d)\n",
    "\n",
    "    # TODO: backward\n",
    "    loss.backward()\n",
    "\n",
    "    # TODO: update\n",
    "    optimizer.step()\n",
    "\n",
    "    if epoch % 5 == 0:\n",
    "        print(\"Epoch\", epoch, \"| loss =\", float(loss))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c894744",
   "metadata": {},
   "source": [
    "## 8) Evaluation\n",
    "\n",
    "1. Apply `sigmoid` to the logits\n",
    "2. Convert probabilities to predictions\n",
    "3. Compute **accuracy** on the validation set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "b10b706c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.5600, device='mps:0')"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: evaluation\n",
    "with torch.no_grad():\n",
    "    logits = model.forward(X_val_d)\n",
    "    probs = sigmoid(logits)\n",
    "    preds = (probs >= .5).float()\n",
    "\n",
    "accuracy = (preds == y_val_d).float().mean()\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9698541c",
   "metadata": {},
   "source": [
    "## 9) Reflection questions (answer inside the markdown)\n",
    "\n",
    "1. Why do we **not** apply sigmoid inside the model?\n",
    "> \n",
    "\n",
    "2. What would happen if we removed all ReLU activations?\n",
    "> If we removed all ReLU activations, the Multi-Layer Perceptron would perform an operation which is equivalent to a linear transformation of the inputs. ReLU activations add nonlinear transformation accross the layers.\n",
    "\n",
    "3. How does this toy problem relate to image classification?\n",
    "> This toy problem relate to image classification in the sense that images can be seen as vectors if flattened. And the use of Deep Learning leverages nonlinear transformations in order to recongnize patterns and local structures.\n",
    "\n",
    "Write short answers (2â€“3 lines each).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be9f2ed3",
   "metadata": {},
   "source": [
    "## 10) Bridge to Computer Vision\n",
    "\n",
    "So far:\n",
    "- inputs = vectors of size 3\n",
    "- layers = fully-connected\n",
    "\n",
    "Next session:\n",
    "- inputs = images `(B, C, H, W)`\n",
    "- layers = convolutions\n",
    "- same training logic\n",
    "\n",
    "ðŸ‘‰ **Architecture changes, learning principles stay the same.**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f479aad6",
   "metadata": {},
   "source": [
    "## Part II â€” Training on MNIST\n",
    "\n",
    "Check the next notebook"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
